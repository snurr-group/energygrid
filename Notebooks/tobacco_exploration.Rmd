---
title: "Retraining and exploration of the ToBaCCo MOFs"
author: "Ben Bucior"
date: "November 9, 2017"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(readr)
library(ggplot2)
library(stringr)

library(purrr)
library(readxl)

library(testthat)

library(caret)
library(glmnet)

knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())

theme_set(theme_bw(base_size=16) + theme(aspect.ratio=1))  # Default ggplot2 params
```

## Data import and processing

```{r load.data, include=FALSE}
h2_types <- paste0("h2.", c("g.L", "mol.kg", "wtp"))
tobacco_data <- read_xlsx(
  "BigData/CrystGrowthDesign_SI.xlsx",
  sheet = "data",
  skip = 3, na = "inf",
  col_names = c(
    "MOF.ID",
    "vf", "vsa", "gsa", "pld", "lcd",
    paste0(h2_types, ".100.77"),
    paste0(h2_types, ".100.130"),
    paste0(h2_types, ".100.200"),
    paste0(h2_types, ".100.243"),
    paste0("h2.qst.6.", c(77, 130, 200, 243)),
    paste0("ch4.", rep(c("v.v.", "mg.g."), 2), c("100.298", "100.298", "65.298", "65.298")),
    "ch4.qst.6.298",
    paste0("xe.kr.1.", c("xe", "kr", "select")),
    paste0("xe.kr.5.", c("xe", "kr", "select")),
    "topology",
    paste0("n1.", c("sym", "character", "ID")),
    paste0("n2.", c("sym", "character", "ID")),
    "cbb.ID"
    )
  )
tobacco_codes <- read_table2("BigData/mofs_map.dat", col_names = c("MOF.ID", "python.id"), col_types="ic")

tobacco_data <- tobacco_data %>% left_join(tobacco_codes, by="MOF.ID")

tobacco_data <- tobacco_data %>% 
  mutate("n1.name" = str_c("sym", n1.sym, ifelse(n1.character=="organic", "on", "mc"), n1.ID, sep="_")) %>% 
  mutate("n2.name" = str_c("sym", n2.sym, ifelse(n2.character=="organic", "on", "mc"), n2.ID, sep="_"))

# Translate between Scotty's ID and the traditional ToBaCCo filename
scotty_codes <- read_tsv("BigData/tobacco-20171114/key.tsv", col_names = c("filename", "id"), col_types="cc")
scotty_codes <- scotty_codes %>% mutate(python.id = str_sub(filename, 1, -5))  # trim .cif suffix
tobacco_data <- tobacco_data %>% inner_join(scotty_codes, by="python.id")

DATA_SPLIT <- c(0.4, 0.4, 0.2)
R_GAS_KJ <- 8.314 / 1000
source("R/regression_and_features.R")  # Get regression utilities
```

```{r load_low_p}
# Also import the new low pressure data
# Note: if you change the data source in low_p_data_src, you need to re-import tobacco_codes above,
# since this block performs inner joins to only keep fully available data.
low_p_data_src <- "yamil_6bar"

if (low_p_data_src == "no_uc_77k") {  # 2 bar, but GCMC script likely only used a 1x1x1 unit cell
  low_p_h2_data <- read_tsv(
    "BigData/tobacco-20171114/clean-gcmc/comb-volume-77k.tsv",
    col_names = c("tob.num", "id", "h2.v.v.2.77", "h2.err.v.v.2.77"),  # TODO: verify that this is 2 bar, 77 K data for H2, and GCMC errors
    col_types = "icnn"
    )
  low_p_h2_data <- low_p_h2_data %>% 
    mutate(`h2.g.L.2.77` = `h2.v.v.2.77` * 2.0 / 22.4) %>% 
    mutate(`h2.err.g.L.2.77` = `h2.err.v.v.2.77` * 2.0 / 22.4)
  tobacco_data <- tobacco_data %>% inner_join(low_p_h2_data, by="id")  # For now, let's only import complete data
  tobacco_data <- tobacco_data %>% mutate(h2.deliv.77 = h2.g.L.100.77 - h2.g.L.2.77)
} else if (low_p_data_src == "yamil_6bar") {  # 77 K / 6 bar from EES paper, Yamil, 2017-11-15
  # Similar format to the CrystGrowthDesign spreadsheet above, but with fewer columns to import
  low_p_h2_data_raw <- read_xlsx(
    "BigData/Emails/tobacco-yamil-20171115/EES-SI-07-18-2016.xlsx",
    sheet = "data",
    skip = 3, na = "inf",
    col_names = c(
      "MOF.ID",
      "vf", "vsa", "gsa", "pld", "lcd",
      paste0(h2_types, ".100.77"),
      paste0(h2_types, ".5.160"),
      paste0(h2_types, ".6.77"),
      paste0("h2.qst.", c("6.77", "5.160")),
      "topology",
      paste0("n1.", c("sym", "character", "ID")),
      paste0("n2.", c("sym", "character", "ID")),
      "cbb.ID"
      )
    )
  # tobacco_data[1,1] = 234052409235  # Tested the next piece of test code by messing up one of the ID's
  # Ensure data consistency: that compositions for the first MOF.ID column are the same
  # anti_join will look for rows that mismatch within these columns
  temp_mof_id_mismatches <- low_p_h2_data_raw %>%
    anti_join(tobacco_data, by=c(
      "MOF.ID", "topology",
      paste0("n1.", c("sym", "character", "ID")),
      paste0("n2.", c("sym", "character", "ID"))
      )) %>% 
    nrow
  expect_equal(temp_mof_id_mismatches, 0)  # Now we can safely use MOF.ID to join
  # Alternatively, we could have just performed an inner join on all of these columns
  low_p_h2_data <- low_p_h2_data_raw %>% 
    select(c(1, 10:15, 17))  # MOF.ID and the new H2 data (not 100 bar cryo)
  tobacco_data <- tobacco_data %>% inner_join(low_p_h2_data, by="MOF.ID")
  tobacco_data <- tobacco_data %>% mutate(h2.deliv.77 = h2.g.L.100.77 - h2.g.L.6.77)
}

```

```{r load_grids}
if (!exists("raw_grids_h2")) {
  raw_grids_h2 <- read_rds("BigData/Robj/tobacco_h2.Rds")
  # TODO: we should calculate the base histogram with less granularity (0.05 kJ/mol instead of 0.01) to considerably reduce file and processing size
}
```

```{r partition_data}
tob_y_to_join <- tobacco_data %>% 
  rename(g.L = h2.deliv.77) %>% 
  select(id, g.L) %>% 
  filter(!(is.na(g.L) | g.L < 0))  # Clean up unphysical MOFs
complete_ids <- raw_grids_h2 %>% 
  select(id) %>% 
  unique() %>% 
  inner_join(tob_y_to_join, by="id") %>% 
  select(id) %>% 
  unlist

tob_y_to_join <- tob_y_to_join %>% filter(id %in% complete_ids)
grids_h2 <- raw_grids_h2 %>% filter(id %in% complete_ids)

tob_hist_sets <- partition_data_subsets(grids_h2, tob_y_to_join, DATA_SPLIT)
```

Long-term, we also may consider moving this to a modular, independent R script to generate the figures all separately.  (Save models as R objects and import them individually as necessary, then ggsave the plots as their publication-ready formats)

## Proof-of-concept modeling
Let's run a quick ridge regression model on the ToBaCCo MOF set to see if the performance is similar to the hMOF results presented at AIChE.

Note: had to temporarily test with the hMOFs instead of ToBaCCo: the ToBaCCo MOFs lack sufficient diversity in volumetric uptake: they're considerably higher than the hMOFs, but also more tightly clustered which prevents the model from sufficiently generalizing.  Training on hMOFs and testing on ToBaCCo MOFs works great, unless we use some advanced sampling techniques on the ToBaCCo MOFs.

```{r model_proof_of_concept}
source("R/plot_hists.R")
source("R/regression_and_features.R")
source("R/get_energy_stats.R")
source("R/plot_diagnostics.R")

source("R/load_data.R")
hmof_h2_grid <- read_rds("BigData/Robj/hmof_h2.Rds")
hmof_h2_grid <- hmof_h2_grid %>%
  mutate(str_id = str_sub(id, 6, -1)) %>% # strip the hMOF- prefix
  mutate(id = as.integer(str_id)) %>% 
  select(-str_id)
hmof_y_to_join <- gcmc_data %>% 
  select(id, g.L) %>% 
  filter(!(is.na(g.L) | g.L < 0))
hmof_hist_sets <- partition_data_subsets(hmof_h2_grid, hmof_y_to_join, DATA_SPLIT)
# Note: since we're starting with 2500 hMOFs, 40% for training is still 1000, so that works out great.

# First, let's plot a ridge regression model against ToBaCCo
temp_tob_part_mod <- run_model_on_partitions(tob_hist_sets, tob_y_to_join, default_binspec, 0)
print(temp_tob_part_mod)
parity_plot(temp_tob_part_mod$trained_mod$y, pred_glmnet(temp_tob_part_mod$trained_mod, temp_tob_part_mod$trained_mod$orig_x), "#CA7C1B", alpha=0.5)

# Final saved results are ridge (alpha = 0)
for (perf_alpha in c(1, 0)) {
  hmof_partitioned_mod <- run_model_on_partitions(hmof_hist_sets, hmof_y_to_join, default_binspec, perf_alpha)
  print(hmof_partitioned_mod)
  trained_model <- hmof_partitioned_mod$trained_model
  trained_mod <- hmof_partitioned_mod$trained_mod
}
plot(hmof_partitioned_mod$plots$parity_bw)
```

As a diagnostic, I tried training the ToBaCCo data on 6 bar, 77 K data that may have more accurate GCMC.  The result is a different level of fit than previously.  Q2 has shot up from 0.04 to 0.42, but RMSE increased from 4.7 to 6.0, and MAE from 3.1 to 3.5.  There's also quite a few MOFs now on the peripheries of the model, either in the upper 30's g/L predicted or GCMC lines.


```{r tobacco_diagnostic}
# Try the hMOF model on the ToBaCCo data for sampling

# First, how does its distribution of y values vary?  I think the model above is overfitting, given its mean capacity of 38 g/L
hist(tob_y_to_join$g.L)

# COPIED FROM ABOVE: MAKE THIS A SUBROUTINE.
# MAYBE WE NEED A MODEL SETUP OBJECT, INCLUDING BINS AND OTHER PARAMS?
# Performance on the test data, which hasn't yet been used for anything
testing_desc <- tob_hist_sets$testing %>% 
  stepped_hist(1.0, 1.0, -20, 1.0) %>% 
  spread(key=bin, value=metric)
y_act <- testing_desc %>%
  left_join(tob_y_to_join, by="id") %>% 
  rename(y = g.L) %>% 
  .$y
testing_ids <- testing_desc %>% select(id)
testing_desc <- testing_desc %>% select(-id)

y_pred <- pred_glmnet(trained_mod, testing_desc)
postResample(pred=y_pred, obs=y_act) %>% print

# NEW FOR COLORING
has_hmof_topology <- testing_ids %>%
  select(id) %>% 
  left_join(tobacco_data, by="id")
has_hmof_topology <- (has_hmof_topology$topology %in% c("pcu", "sra", "diab", "tbo", "nbo", "fcu"))

p <- parity_plot(y_act, y_pred, ifelse(has_hmof_topology, "red", "gray"), 0.25)
p <- p + ylab(paste0("Predicted uptake (ridge regression)"))
print(p)

hist(y_act - y_pred)

  
  
# For diagnosis, we might consider plotting the various distributions to see how similar they are between the hMOFs and ToBaCCo MOFs
standardize(trained_mod, testing_desc) %>% .$`Inf` %>% hist

# Compare z/y/beta plots for the training hMOFs and test ToBaCCo MOFs
plot_bin_z_vs_y(trained_mod$x, trained_mod$y, coef_tbl(trained_mod$mod))
plot_bin_z_vs_y(standardize(trained_mod, testing_desc), y_act, coef_tbl(trained_mod$mod))
# What happens if we compare against the model instead of GCMC?  What does the "Inf" bin look like?
plot_bin_z_vs_y(standardize(trained_mod, testing_desc), y_pred, coef_tbl(trained_mod$mod))

# Finally, what are the distributions of z-scores (and actual values) between ToBaCCo and hMOFs?
x_distr <- function(x) {
  x %>% 
    gather(key="bin", value="value") %>% 
    ggplot(aes(value)) +
    geom_histogram() +
    facet_wrap(~bin, scales="free") +
    theme(text = element_text(size = 8))
}

x_distr(trained_mod$x)
x_distr(standardize(trained_mod, testing_desc))
# And the non-trainsformed versions
x_distr(select(trained_mod$orig_x, c("17", "18", "19", "20", "21", "Inf")))
x_distr(select(testing_desc, c("17", "18", "19", "20", "21", "Inf")))
```

What ToBaCCo MOFs have the most egregious error?

```{r top_tobacco_err}
which(abs(y_pred - y_act) > 10) %>% length
length(y_pred)  # okay, so it's a pretty big number of them
testing_ids %>% 
  bind_cols(y_pred = as.numeric(y_pred), y_act = y_act) %>% 
  mutate(abs_err = abs(y_pred - y_act)) %>% 
  arrange(desc(abs_err)) %>% 
  inner_join(tobacco_data, by="id") %>% 
  select(id, abs_err, y_pred, y_act, filename) %>% 
  #filter(str_detect(filename, "ith_sym_4_on_6*")) %>% 
  View

```


## Revisiting AIChE figures
At any rate, we should see what the hMOF model looks like for betas, multiple pressures, different gases, etc.

```{r hmof_betas}
# Deliverable capacity
base_hist <- hmof_h2_grid %>% 
  filter(id == 71) %>% 
  plot_hist_bins(default_binspec)

base_hist %>% overlay_cat_betas(coef_tbl(trained_mod$mod), default_binspec)

# New figure 11/17 to look at effect of PLD
hmof_training_dat_with_id <- hmof_hist_sets$training %>% 
  stepped_hist_spec(default_binspec) %>% 
  spread(key=bin, value=metric)
hmof_training_dat_with_id %>% 
  select(-id) %>% 
  pred_glmnet(trained_mod, .) %>%
  bind_cols(y_pred=., id=select(hmof_training_dat_with_id, id)) %>% 
  #left_join(hmof_y_to_join, by="id") %>% 
  left_join(gcmc_data, by="id") %>% 
  mutate(y_err = abs(y_pred - g.L)) %>% 
  #arrange(desc(y_err)) %>% 
  ggplot(aes(y_err, dpd)) + geom_point()

#stepped_hist_spec()
#parity_plot(temp_tob_part_mod$trained_mod$y, pred_glmnet(temp_tob_part_mod$trained_mod, #temp_tob_part_mod$trained_mod$orig_x), "#CA7C1B", alpha=0.5)

# Individual components on hydrogen (repeat the full model analysis workflow)
# Relevant code from plot_diagnostics.R:run_model_on_partitions
# trained_model <- run_bin_model(
#     partitioned_hists$training, y_with_id,
#     binspec["step"], binspec["width"],
#     binspec[c("from", "to")],
#     alpha=alpha
#     )
#   trained_mod <- trained_model$fitted_model[[1]]
#   results$trained_model <- trained_model
#   results$trained_mod <- trained_mod
p_hi_model <- hmof_y_to_join %>% 
  select(id) %>% 
  left_join(gcmc_data, by="id") %>% 
  select(id, va100bar) %>% 
  rename(g.L = va100bar) %>% 
  run_bin_model(hmof_hist_sets$training, ., default_binspec["step"], default_binspec["width"], default_binspec[c("from", "to")])

p_lo_model <- hmof_y_to_join %>% 
  select(id) %>% 
  left_join(gcmc_data, by="id") %>% 
  select(id, va2bar) %>% 
  rename(g.L = va2bar) %>% 
  run_bin_model(hmof_hist_sets$training, ., default_binspec["step"], default_binspec["width"], default_binspec[c("from", "to")])

list(`100 bar` = p_hi_model$fitted_model[[1]]$mod, `2 bar` = p_lo_model$fitted_model[[1]]$mod) %>% 
  map_dfr(coef_tbl, .id="cat") %>% 
  overlay_cat_betas(base_hist, ., default_binspec)

```


## New analysis
### Testing models on high pressure data only
Perhaps ToBaCCo will work better only on one pressure, since we already have data available for 100 bar for both hMOFs and ToBaCCo.  Let's see how the model looks while waiting to fill in the low pressure 2 bar data (since we only have 6 bar available).

```{r transfer_high_p}
p_hi_mod <- p_hi_model$fitted_model[[1]]

# MODIFIED FROM COPY ABOVE: MAKE THIS A SUBROUTINE.
# MAYBE WE NEED A MODEL SETUP OBJECT, INCLUDING BINS AND OTHER PARAMS?
# Performance on the test data, which hasn't yet been used for anything
hi_testing_desc <- tob_hist_sets$testing %>% 
  stepped_hist(1.0, 1.0, -20, 1.0) %>% 
  spread(key=bin, value=metric)
tob_y_hi_to_join <- tobacco_data %>% 
  rename(g.L = h2.g.L.100.77) %>% 
  select(id, g.L) %>% 
  filter(!(is.na(g.L) | g.L < 0))  # Clean up unphysical MOFs
tob_y_hi_to_join <- tob_y_hi_to_join %>% filter(id %in% complete_ids)
hi_y_act <- hi_testing_desc %>%
  left_join(tob_y_hi_to_join, by="id") %>% 
  rename(y = g.L) %>% 
  .$y
hi_testing_ids <- hi_testing_desc %>% select(id)
hi_testing_desc <- hi_testing_desc %>% select(-id)

hi_y_pred <- pred_glmnet(p_hi_mod, hi_testing_desc)
postResample(pred=hi_y_pred, obs=hi_y_act) %>% print

### older NEW FOR COLORING
hi_has_hmof_topology <- hi_testing_ids %>%
  select(id) %>% 
  left_join(tobacco_data, by="id")
hi_has_hmof_topology <- (hi_has_hmof_topology$topology %in% c("pcu", "sra", "diab", "tbo", "nbo", "fcu"))

p <- parity_plot(hi_y_act, hi_y_pred, ifelse(has_hmof_topology, "red", "gray"), 0.3)
p <- p + ylab(paste0("Predicted uptake (ridge regression)"))
print(p)

hist(hi_y_act - hi_y_pred)

hi_testing_ids %>% nrow

hi_testing_ids[(hi_y_act > 45 & hi_y_pred < 40),] %>% 
  left_join(tobacco_data, by="id") %>% 
  select(id, topology, filename)
```

### Consistency between overlapping structures (MOF-5)
One of the best diagnostics will be inspecting MOFs that we expect to be in common between the two databases (e.g. hMOF-0 and tobmof6018).  Later, we could consider expanding this to a whole set of MOFs. in common, if of interest.

```{r db_consistency}
ad_hoc_h2_grid <- read_rds("BigData/Robj/ad_hoc.Rds")
# id "Bad" refers to a corrupted CIF for a completely different MOF.
plot_mof_minimal(ad_hoc_h2_grid, "hypotheticalMOF0", default_binspec)
plot_mof_minimal(ad_hoc_h2_grid, "pcu_sym_6_mc_3_L_12", default_binspec)

# First try a density plot.  The stats are acting strange, so let's generate it manually
#ad_hoc_h2_grid %>%
#  group_by(id) %>% mutate(dens = counts / sum(counts)) %>% ungroup() %>%
#  ggplot(aes(lower, weight=dens, col=id)) +
#  stat_density(adjust = 1/5, size = 2, geom = "line")

# Next let's look at the hist bins directly, so we can also see what's going on with "Inf"
ad_hoc_h2_grid %>% 
  stepped_hist_spec(default_binspec) %>% 
  mutate(height = metric) %>% 
  inner_join(color_from_binloc(bin_loc_from_spec(default_binspec)), by="bin") %>% 
  ggplot(aes(loc, height, col=id)) +
  #geom_line(size = 1.5, alpha = 0.7) +
  geom_point(alpha = 0.7) + geom_line(size=0.5) +
  labs(x="Energy (kJ/mol)")
# What are the 100 bar uptakes for these MOFs?
gcmc_data %>% filter(id == 0) %>% select(va100bar)
tobacco_data %>% filter(filename=="pcu_sym_6_mc_3__L_12.cif") %>% select(h2.g.L.100.77)

# What about the predictions on these MOFs?
ad_hoc_raw_bins <- ad_hoc_h2_grid %>% 
  filter(id != "bad") %>% 
  stepped_hist_spec(default_binspec) %>% 
  spread(key=bin, value=metric)
ad_hoc_raw_bins
ad_hoc_raw_bins %>% 
  select(-id) %>% 
  pred_glmnet(p_hi_mod, .)

# How consistent is the number of grid points/samples on these two materials?
ad_hoc_h2_grid %>% 
  group_by(id) %>% 
  summarize(sum(counts))
```

### Plotting by color
Next, let's see if we can figure out the discrepancy in high pressure loading from a graphical argument.  We have several MOF textural properties in the tobacco_data spreadsheet.  Based on the previous block, it also might be worthwhile double checking the level of sampling for each MOF.  This block will use the model and data mentioned in the block `transfer_high_p` above.


```{r plot_err_trends}
hi_data <- hi_testing_ids %>% 
  select(id) %>% 
  left_join(tobacco_data, by="id")
hi_data <- tob_hist_sets$testing %>% 
  group_by(id) %>% 
  summarize(sampling = sum(counts)) %>% 
  select(id, sampling) %>% 
  ungroup %>% 
  inner_join(hi_data, by="id")

summary(hi_data$sampling)
# Manually use parity plot so we have more fine grained control

qplot(hi_y_act, hi_y_pred, col=ifelse(hi_data$sampling > 30000, 30000, hi_data$sampling), alpha=I(0.4)) +
  xlab("'Actual' uptake (GCMC simulations)") +
  ylab("Predicted uptake (ridge regression)") +
  expand_limits(x = 0, y = 0) +
  scale_x_continuous(limits = c(0,70)) +
  scale_y_continuous(limits = c(0,70)) +
  scale_color_gradientn(colors=c("red", "black", "blue"), name=NULL) +
  parity_line
# Based on this analysis, let's revisit the apparently worst points
hi_testing_ids %>% 
  bind_cols(hi_y_pred = as.numeric(hi_y_pred), hi_y_act = hi_y_act) %>% 
  mutate(abs_err = abs(hi_y_pred - hi_y_act)) %>% 
  arrange(desc(abs_err)) %>% 
  #inner_join(tobacco_data, by="id") %>% 
  inner_join(hi_data, by="id") %>% 
  select(id, abs_err, hi_y_pred, hi_y_act, filename, sampling) %>% 
  View
# Alternatively,
hi_errs_with_data <- hi_testing_ids %>% 
  bind_cols(hi_y_pred = as.numeric(hi_y_pred), hi_y_act = hi_y_act) %>% 
  mutate(abs_err = abs(hi_y_pred - hi_y_act)) %>% 
  inner_join(hi_data, by="id")
hi_errs_with_data %>% 
  mutate(sampling = ifelse(sampling > 30000, 30000, sampling)) %>% 
  ggplot(aes(abs_err, sampling, col=vf)) +
  geom_point()
# Or this way, with two plots
hi_errs_with_data %>% 
  mutate(num_pts = if_else(sampling < 15000, "Low number of points", "At least 25^3")) %>% 
  ggplot(aes(hi_y_act, hi_y_pred, col=abs_err)) +
  geom_point() + 
  facet_wrap(~num_pts) +
  parity_line
```

This plot reminds me that there's a simple way to increase the number of variables I can view simultaneously, especially when factors are involved: summary!  However, it's hard to compare proportions to look for differences in representativenesss, other than noticing things like the null linker being a problem.

```{r summary_err_hi}
hi_err_for_summary <- hi_errs_with_data %>% 
  #select(abs_err, vf, n1.sym, n1.character, n1.ID, n2.sym, n2.character, n2.ID, cbb.ID, pld, vsa) %>% 
  select(abs_err, vf, n1.name, n2.name, cbb.ID, pld, vsa) %>% 
  mutate_at(3:5, factor)
cat("Full set of tested ToBaCCo MOFs:\n")
summary(hi_err_for_summary)
cat("ToBaCCo MOFs with high error (> 10g/L):\n")
summary(filter(hi_err_for_summary, abs_err > 10))
```

Now let's look at a few other plots I was intending to view.
```{r misc_plots}
ggplot(hi_errs_with_data, aes(abs_err, vf)) + geom_point()
ggplot(hi_errs_with_data, aes(abs_err, vsa)) + geom_point()
ggplot(hi_errs_with_data, aes(abs_err, pld)) + geom_point()

# Also plot y_err vs. z to see if specific bins are causing problems
plot_bin_z_vs_y(
  standardize(p_hi_mod, hi_testing_desc),
  hi_errs_with_data$abs_err,
  coef_tbl(p_hi_mod$mod)
  ) +
  ylab("Absolute error in y")

# But if it's a convergence issue, why don't we see it as bad in the hMOFs?
# Let's take a look at the PLD plot
# (see above.  We had to use DPD since that's all we have in the spreadsheet)
```

### Retry a single point
See revised `ad_hoc_raw_bins` definition and data.frame above. It's getting a prediction of 51.91267 vs. an actual value of 54.553571 for `ith_sym_4_on_7_sym_13_mc_12_L_40.cif`, so that's all the problem was.  For some reason, the file on the testing folder has 2197 lines versus 21952 in my version.


### Figure showing bin robustness
Eventually, we could move this to a separate function in plot_hists.R, but it doesn't seem like there's much point in doing that since we only need a single figure.

```{r bin_robusness}
if (!exists("hyper_tuned_hist")) {
  hyper_tuned_hist <-
    seq(0.25, 2.5, 0.25) %>% # eventually consider 0.25-2.5 in quarter increments
    map_dfr(
      function(x) run_bin_model(
        e_data = hmof_hist_sets$hyperparam,
        y_with_id = hmof_y_to_join,
        step = x, width = x,
        bin_lims = c(default_binspec["from"], default_binspec["to"]),
        lambda = NULL, alpha = 0
        )
      ) %>% 
    # Warning: the above output cannot be viewed without deleting the fitted_model and id_list list columns
    (function(x) {
      y <- tibble()
      for (rownum in 1:nrow(x)) {
        curr_row <- x[rownum,]
        y <- coef_tbl(curr_row[[1,"fitted_model"]]$mod) %>% 
          mutate(q2 = curr_row$q2, binwidth = curr_row$width) %>% 
          inner_join(
            bin_loc_from_spec(c(
              from=curr_row$bin_lo,
              to=curr_row$bin_hi,
              step=curr_row$step,
              width=curr_row$width
              )),
            by="bin"
            ) %>% 
          bind_rows(y, .)
      }
      y
    })(.)  # run the anonymous function
}

plot_robustness_bin_gap <- 0.05
plot_robustness_beta_max <- 5
hyper_tuned_hist %>% 
  mutate(beta = ifelse(beta > plot_robustness_beta_max, plot_robustness_beta_max, beta)) %>% 
  mutate(beta = ifelse(beta < -plot_robustness_beta_max, -plot_robustness_beta_max, beta)) %>% 
  mutate(lower = lower + plot_robustness_bin_gap, upper = upper - plot_robustness_bin_gap) %>% 
  ggplot(aes(
    x = binwidth,
    ymin = lower,
    ymax = upper,
    color = beta
  )) +
  geom_linerange(size=2) +
  coord_flip() +
  scale_color_gradientn(
    colors = c("red", "darkgray", "blue"),
    limits = c(-plot_robustness_beta_max, plot_robustness_beta_max),
    breaks = c(-plot_robustness_beta_max, 0, plot_robustness_beta_max),
    labels = c(paste0(-plot_robustness_beta_max,"-"), "0", paste0(plot_robustness_beta_max,"+")),
    name=expression(beta[ridge])
    ) +
  labs(
    y = "Energy (kJ/mol)",
    x = "Width of histogram bins (kJ/mol)"
  )
# See relevant ggplot documentation at http://ggplot2.tidyverse.org/reference/geom_linerange.html

# This figure highlights a suspicion I had, that upper bound is based on where there aren't any bins
# remaining in the binspec.  An alternate approach would be centering this to zero instead of the lower
# bound, then only including one bin (or up to bin max??) before cutting it off.

# Now ask, how consistent is the performance among the different models?
hyper_tuned_hist %>% 
  select(binwidth, q2) %>% 
  unique
# TODO: consider reporting RMSE and/or MAE, possibly from the training data?

```

Three things stand out to me as particularly noteworthy from this analysis.

1. As hypothesized/hoped, the model is quite robust to the histogram parameter selection.  As bin size decreases, the magnitude of beta decreases since the effect is spread out over multiple adjacent bins.
2. The left hand side cuts out at approximately the same place, because that's where the variation in the hMOF database goes to zero.
3. Performance, at least as characterized by Q2, slightly decreases with coarser bins, but remains quite good (0.95+).

### Other ideas to try and action items

TODO: methane
Cool plot showing histogram bin parameters

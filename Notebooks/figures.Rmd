---
title: "Generating figures for the manuscript"
author: "Ben Bucior"
date: "December 20, 2017"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r setup_data, include=FALSE}
# Has to be run in a separate block as above
source("Notebooks/setup_data.R")
library(plotly)
```

```{r setup_figs}
# Setup figure parameters
library(cowplot)
# See [intro documentation](https://cran.r-project.org/web/packages/cowplot/vignettes/introduction.html) and [vignette](https://cran.r-project.org/web/packages/cowplot/vignettes/plot_grid.html)
# Per [RSC guidelines](http://www.rsc.org/journals-books-databases/journal-authors-reviewers/submit-your-article/#figures-graphics-images),
# figures should be single column (8.3cm) or double column (17.1cm) and no longer than 23.3cm.
# For final submission, they like 600 dpi TIFF files.  Before then, let's use smaller figs.
default_dpi <- 300
theme_set(theme_cowplot(font_size = 10))
default_fig_dir <- "Figs"
default_subfig_labels <- paste0("(", letters, ")")

mkdirs(default_fig_dir)
save_ben_fig <- function(p, filename, parent_dir = default_fig_dir, ...) {
  save_plot(
    file.path(parent_dir, filename),
    p,
    base_width = 8.3 / 2.54,  # RSC width in inches
    base_height = NULL,  # calculate from base_aspect_ratio and the width
    dpi = default_dpi,
    ...
    )
}
make_draft <- function(p, msg="DRAFT!") {
  # Derived from cowplot intro
  ggdraw(p) +
    draw_label(msg, angle = 45, size = 72, alpha = .2)
}
save_si_fig <- function(p, filename, parent_dir = default_fig_dir, bheight = 3.3, bwidth = NULL, ...) {
  save_plot(
    file.path(parent_dir, filename),
    p,
    base_width = bwidth,  # defaults to NULL (automatic based on the aspect ratio)
    base_height = bheight,  # Height in inches
    dpi = default_dpi,
    ...
    )
}

# Example:
# hmof_partitioned_mod$plots %$% plot_grid(parity_training, make_draft(parity_testing), ncol=1, labels=default_subfig_labels, label_size=12) %>% save_ben_fig("test.png", nrow = 2)
```

## Figures for manuscript: main text

Recreate (and export) figures in a few blocks.  Possibly will be externalized into a separate script later.

```{r prep_conceptual_figures}
# Figures on adsorption strength (conceptual) and ML workflow (to update, but external pptx in the Box Projects folder)
p_concept_isotherms <- read_tsv(
  "BigData/Emails/isotherm-a-b-20180112/tidy_isotherms.tsv",
  skip=0, col_types="cdd"
  ) %>% 
  mutate(g.L = cm3.cm3 * 2.0 / 22.4)
p_concept_isotherms %>% 
  ggplot(aes(bar, g.L, color=id)) +
  geom_smooth(se=FALSE)
# TODO LATER: might want to collect more data before drawing this figure.  In the meantime, a sketch will be added to the outline.



# Resources for schematic figure in pptx
# loop_cif in c(55, 2000189, 5072190)
# Import ad-hoc grids
ad_hoc_h2_grids <- read_rds("BigData/Robj/adhoc_h2.Rds")
# Run on each, then save to the pptx
for (hid in c(55, 2000189, 5072190)) {
  (ad_hoc_h2_grids %>% 
    filter(id == paste0("hMOF-", hid)) %>% 
    plot_hist_bins(default_binspec) +
    scale_y_continuous() +  # restore y axis line
    coord_cartesian(ylim=c(0,0.50), xlim=c(-8.5, 0.50)) +
    theme_diagram_min +
    theme(aspect.ratio = 1.0)
    ) %>% print
}

```

```{r make_figures}
# Coefficients for ridge regression model
hmof_partitioned_mod <- run_model_on_partitions(hmof_hist_sets, hmof_y_to_join, default_binspec, db_name = "hMOFs")
trained_mod <- hmof_partitioned_mod$trained_mod


base_hist <-
  ad_hoc_h2_grids %>% 
  filter(id == "hMOF-0") %>% 
  plot_hist_bins(default_binspec)
p_beta_orig <- base_hist %>% overlay_cat_betas(coef_tbl(trained_mod$mod), default_binspec)
p_beta_orig

# Beta coefficients for different pressures and temperatures
# For help on NSE in dplyr, see vignette("programming")
library(rlang)  # see also https://github.com/tidyverse/rlang/issues/116
mutate_col_to_gL <- function(df, newcol) {
  mutate(df, g.L = !!sym(newcol))
}
## Previously used for the CH4 plots, but no reason not to adapt it for T and P of H2
p_beta_diff_p <- 
  list(`100 bar` = "va100bar", `2 bar` = "va2bar") %>% 
  map(mutate_col_to_gL, df = gcmc_data) %>%
  map(function(x) run_model_on_partitions(hmof_hist_sets, x, default_binspec)) %>% 
  map(function(x) x$trained_mod$mod) %>% 
  map_dfr(coef_tbl, .id="cat") %>% 
  overlay_cat_betas(base_hist, ., default_binspec)

p_2bar_grids <- hmof_h2_grid %>% filter(id %in% p_2bar_data$id)
p_2bar_sets <- partition_data_subsets(p_2bar_grids, p_2bar_data, DATA_SPLIT)
p_160k_grids <- read_rds("BigData/Robj/hmof_160k.Rds") %>% 
  mutate(id = as.integer(str_sub(id, 6)))  # remove the "hMOF-" header

p_beta_diff_t <- 
  filter(p_160k_grids, id %in% p_2bar_sets$training$id) %>% 
  {list(
    `160 K` = run_bin_model_spec(., mutate(p_2bar_data, g.L = h2.g.L.2.160), default_binspec),
    `77 K` = run_bin_model_spec(p_2bar_sets$training, mutate(p_2bar_data, g.L = va2bar), default_binspec)
    )} %>%
  map(function(x) x$fitted_model[[1]]$mod) %>% 
  map_dfr(coef_tbl, .id="cat") %>% 
  overlay_cat_betas(base_hist, ., default_binspec)
# Generate the plots
plot_grid(
  p_beta_orig,
  p_beta_diff_p + theme(legend.position=c(0, 0.2), legend.direction="horizontal"),
  make_draft(p_beta_diff_t + theme(legend.position=c(0, 0.2), legend.direction="horizontal")),
  ncol=1,
  #align = "v",
  labels=default_subfig_labels, label_size=12
  ) %>%
  save_ben_fig("betas.png", nrow = 3, base_aspect_ratio = 1.5)


# Model fit for hMOF ridge regression model
print(hmof_partitioned_mod)
hmof_partitioned_mod$plots %$%
  plot_grid(
    parity_training,
    parity_testing,
    ncol = 1,
    labels=default_subfig_labels, label_size=12
    ) %>% 
  save_ben_fig("parity.png", nrow = 2)

# Print stats for other databases, including fitting the ToBaCCo data to itself
# tob_y_to_join and tob_hist_sets are defined in setup_data.R
p_tob_mod <- run_model_on_partitions(tob_hist_sets, tob_y_to_join, default_binspec, db_name = "ToBaCCo MOFs")
p_tob_mod
# ...and using the hMOF-trained model directly on the ToBaCCo database
p_tob_from_hmof <- 
  tobacco_data %>% 
  mutate(y_act = fh.h2.g.L.100.77 - fh.h2.g.L.2.77) %>% 
  eval_test_grid(hmof_partitioned_mod$trained_mod, tob_hist_sets$testing, default_binspec, ., db_name = "ToBaCCo MOFs\n(hMOF model)")

# CCDC applicability, etc.
no_cnps <- read_tsv("BigData/Robj/csd_mofs_without_cnps.txt", skip=0, col_names="id", col_types="c")$id
print(paste("Number of CCDC MOFs without CNPS:", length(no_cnps)))
p_ccdc_random <- 
  ccdc_h2_grids %>% 
  filter(id %in% ccdc_gcmc$id) %>% 
  #mutate(has_cnps = !(id %in% no_cnps)) %>% 
  #filter(!(id %in% no_cnps)) %>% 
  eval_test_grid(trained_mod, ., default_binspec, mutate(ccdc_gcmc, y_act=g.L), db_name = "CCDC MOFs\n(hMOF model)")
p_ccdc_parity <- 
  p_ccdc_random$plots$parity_testing

# Generate the (large) figure for model generality
p_tob_mod$plots %$%
  plot_grid(
    parity_training,
    parity_testing,
    p_tob_from_hmof$plots$parity_testing,
    p_ccdc_parity,
    ncol = 2,
    labels=default_subfig_labels, label_size=12
    ) %>% 
  save_ben_fig("general_parity.png", nrow = 2, ncol = 2)



# Robustness to histogram binning strategy
hyper_tuned_hist <- read_rds("BigData/Robj/hyper_tuned.Rds")  # FIXME: This will need to be regenerated
plot_robustness_bin_gap <- 0.05
plot_robustness_beta_max <- 0.5 * BETA_H2_SCALING / 5.0  # match the parameters on the beta plots, scaled back a little bit
p_robust <- 
  hyper_tuned_hist %>% 
  mutate(beta = ifelse(beta > plot_robustness_beta_max, plot_robustness_beta_max, beta)) %>% 
  mutate(beta = ifelse(beta < -plot_robustness_beta_max, -plot_robustness_beta_max, beta)) %>% 
  mutate(lower = lower + plot_robustness_bin_gap, upper = upper - plot_robustness_bin_gap) %>% 
  ggplot(aes(
    x = binwidth,
    ymin = lower,
    ymax = upper,
    color = beta
  )) +
  geom_linerange(size=2) +
  coord_flip() +
  scale_color_gradientn(
    colors = c("red", "darkgray", "blue"),
    limits = c(-plot_robustness_beta_max, plot_robustness_beta_max),
    breaks = c(-plot_robustness_beta_max, 0, plot_robustness_beta_max),
    labels = c(paste("<",-plot_robustness_beta_max), "0", paste(">",plot_robustness_beta_max)),
    name=expression(beta[LASSO])
    ) +
  labs(
    y = "Energy (kJ/mol)",
    x = "Width of histogram bins (kJ/mol)"
  )
save_ben_fig(p_robust, "beta_robustness.png", base_aspect_ratio=1.3)
p_robust


# Methane predictions
p_ch4_vol <- p_2bar_data %>% 
  mutate(g.L = ch4.cm3.cm3.65.298 - ch4.cm3.cm3.5_8.298) %>% 
  run_model_on_partitions(p_ch4_sets, ., ch4_binspec, plot_units="cm\u00B3/cm\u00B3", db_name = "hMOFs")
  # https://en.wikipedia.org/wiki/Unicode_subscripts_and_superscripts
p_ch4_vol$plots$parity_full %>% 
  rescale_ch4_parity()
ad_hoc_ch4_grids <- read_rds("BigData/Robj/adhoc_ch4.Rds")
ch4_base_hist <-
  ad_hoc_ch4_grids %>% 
  filter(id == "hMOF-0") %>% 
  plot_hist_bins(ch4_binspec)
p_beta_ch4 <- 
  list(`5.8 bar` = "ch4.cm3.cm3.5_8.298", `65 bar` = "ch4.cm3.cm3.65.298") %>% 
  map(mutate_col_to_gL, df=p_2bar_data) %>%
  map(function(x) run_model_on_partitions(p_ch4_sets, x, ch4_binspec)) %>% 
  map(function(x) x$trained_mod$mod) %>% 
  map_dfr(coef_tbl, .id="cat") %>% 
  overlay_cat_betas(ch4_base_hist, ., ch4_binspec, scaling = BETA_CH4_SCALING)

p_ch4_vol$plots %$%
  plot_grid(
    parity_training %>% rescale_ch4_parity(),
    parity_testing %>% rescale_ch4_parity(),
    p_beta_ch4 + theme(legend.position=c(0, 0.2), legend.direction="horizontal"),
    ncol = 1,
    rel_heights = c(1, 1, 1.1/1.5),
    labels=default_subfig_labels, label_size=12
    ) %>% 
  #save_ben_fig("ch4_plots.png", nrow = 2, ncol = 2)
  save_ben_fig("ch4_plots.png", nrow = 3, ncol = 1)

```

```{r main_textural}
# TODO thoughts:
# Write a function to generalize model fitting/evaluation
# Test with avsa vs. avsa+navsa, etc.
# Probably should also test against ToBaCCo data, which has been imported but not analyzed

# Maybe also see how necessary ridge regression is for this model.  Maybe MLR isn't good enough for this one?


# Textural property base model
zeo_tsv_names <- c("filename", "LCD", "PLD", "avf", "navf", "density", "avsa", "agsa", "navsa", "nagsa")
zeo_hmof <- read_delim(
  "BigData/quest/PoreChar/all.tsv",
  col_names = zeo_tsv_names,
  col_types = "cddddddddd",  # parse_number doesn't process scientific notation, so we need to use dbl's
  skip = 1,
  delim = " "
  ) %>% 
  mutate(id = as.integer(str_sub(filename, 6)))
zeo_tobmof <- read_delim(
  "BigData/quest/TobPores/all.tsv",
  col_names = zeo_tsv_names,
  col_types = "cddddddddd",  # parse_number doesn't process scientific notation, so we need to use dbl's
  skip = 1,
  delim = " "
  ) %>% 
  mutate(id = filename)  # ToBaCCo id's start with tobmof, so it's already the correct format
textural_data <- 
  zeo_hmof %>% 
  inner_join(gcmc_data, by="id") %>% 
  mutate(y_act = va100bar - va2bar)
zeo_model <- 
  textural_data %>% 
  filter(id %in% hmof_hist_sets$training$id) %>%  # TODO: check that nfit is actually 1000, once textural property simulations are complete
  select(id, y_act, LCD, PLD, avf, density, agsa, avsa) %>% 
  select(-id) %>% 
  {fit_glmnet(select(., -y_act), .$y_act)}
parity_plot(zeo_model$y, pred_glmnet(zeo_model, zeo_model$orig_x))

zeo_testing_x <- 
  textural_data %>% 
  filter(id %in% hmof_hist_sets$testing$id) %>% 
  select(id, y_act, LCD, PLD, avf, density, agsa, avsa) %>% 
  select(-id)
parity_plot(zeo_testing_x$y_act, pred_glmnet(zeo_model, select(zeo_testing_x, -y_act)))
postResample(pred=pred_glmnet(zeo_model, select(zeo_testing_x, -y_act)), obs=zeo_testing_x$y_act)

coef_tbl(zeo_model$mod)
# also consider which variables were used earlier...we have some redundancies which might be coding nonlinearities?
# alternatively fitting on the ToBaCCo MOFs or something similarly non-diverse??
# see also methane, of course
  

# OLD CONTENT:
# Models based on textural properties
# TODO: all of the "good" models so far have been based on methane.  Can we reproduce the good predictivity for CH4 using MLR?  Maybe the problem is like hydrogen storage, where high P is predicted by Chahine's rule
# Serves as a baseline for how well the energy histogram is working.
# Selected properties based on a quick literature review of ML:
# We should use rho, VF, VSA/GSA, and potentially LCD or other pore diameters.
# Cory Simon, EES 2015, 1190-1199: Density, VF, largest included sphere, AVSA
# Fernandez, JPCC 2013, 7681-7689: DPD, VF, GSA (and VSA)
# Pardakhti, ACS Comb Sci 2017, 7681-7689: VF, GSA, density, DPD, LCD, Interp. cap, Cat nets
# Plus chemical properties: element counts, metal type, degree of saturation, metallic %, ratios of atom types
# Thornton, Chem Mater 2017, 2844-2854: VF, density, adsorption energy (kJ/mol), pore diameter, GSA, VSA
# First, prepare the input data
textural_props <- 
  gcmc_data %>% 
  mutate(h2.deliv.77 = va100bar - va2bar) %>% 
  select(id, vf=void.frac, lcd, gsa=surf.area..mass., vsa=surf.area..vol., h2.deliv.77) %>% 
  mutate(id = str_c("h", id))
textural_props <- 
  tobacco_data %>% 
  mutate(h2.deliv.77 = fh.h2.g.L.100.77 - fh.h2.g.L.2.77) %>% 
  select(id, vf, lcd, gsa, vsa, h2.deliv.77) %>% 
  bind_rows(hMOF = textural_props, ToBaCCo = ., .id = "db") %>% 
  na.omit
# Run ridge regression models and generate parity plots in the same style as the energy grid method
textural_hmofs <- 
  textural_props %>% 
  filter(db == "hMOF") %>% 
  select(-db)
textural_training_rows <- sample(nrow(textural_hmofs), 1000)
textural_mod <- 
  textural_hmofs %>% 
  .[textural_training_rows,] %>% 
  select(-id) %>% 
  {fit_glmnet(select(., -h2.deliv.77), .$h2.deliv.77)}
# (will probably be the same fit_glmnet function)
textural_pred <- 
  textural_hmofs %>% 
  .[-textural_training_rows,] %>% 
  select(-id, -h2.deliv.77) %>% 
  pred_glmnet(textural_mod, .)
textural_act <- textural_hmofs[-textural_training_rows, "h2.deliv.77"]
parity_plot(textural_act, textural_pred, alpha=0.1)
postResample(pred=textural_pred, obs=textural_act)
textural_mod$lambda






```


```{r ccdc_selection}
#```{r ccdc_selection, eval=FALSE, include=FALSE}
# Prepare list of top CCDC MOFs for additional screening
# no_cnps is imported when generating the CCDC parity plot above, from work in filter_ccdc_chemistry.R

if (!exists("ccdc_predicted")) {
  ccdc_predicted <- 
    ccdc_h2_grids %>% 
    pred_grid(trained_mod, ., default_binspec)
}

ccdc_predicted %>% arrange(desc(y_pred)) %>% View

ccdc_predicted %>% arrange(desc(y_pred)) %>% top_n(750, y_pred) %>% arrange(id) %>% select(id) %>% write_tsv("BigData/Output/top_ccdc.txt", col_names=FALSE)  # A reasonable number of the top candidates.  For the paper, 50 g/L might be a better threshold, since it's only 200 structures and a nice round number.

ccdc_top500 <- ccdc_predicted %>% arrange(desc(y_pred)) %>% top_n(500, y_pred)


# Get the difference of the two lists to submit to mateo for additional screening
old_screening <- read_tsv("BigData/Output/top_ccdc_20180122.txt", skip=0, col_names="id", col_types="c")$id
old2_screening <- read_tsv("BigData/Output/new_ccdc_20180131.txt", skip=0, col_names="id", col_types="c")$id  # only ~250
ccdc_predicted %>% arrange(desc(y_pred)) %>% top_n(500, y_pred) %>% filter(!(id %in% old_screening) & !(id %in% old2_screening)) %>% arrange(id) %>% select(id) %>% write_tsv("BigData/Output/new_ccdc.txt", col_names=FALSE)  # only 11 in the top 750 in round three, none of which are in the top 600.  Get around to this if there's any remaining in the top 500 in the final model.


parse_vol_data <- function(filename) {
  read_tsv(
    filename,
    skip=1,
    col_names=c("id", paste0("fh.h2.g.L.", c("2.77", "2.77.err", "100.77", "100.77.err"))),
    col_types="cdddd"
    ) %>% 
  mutate_at(vars(starts_with("fh.h2")), funs(. * 2.0 / 22.4)) %>% 
  mutate(g.L = fh.h2.g.L.100.77 - fh.h2.g.L.2.77)
}
screening_gcmc <- 
  list(orig="ScreenCSD", extended="ExtraCSD2") %>% 
  map_chr(~paste0("BigData/Mateo/EnergyGrid/", .x, "/volume.tsv")) %>% 
  #list("BigData/Mateo/EnergyGrid/ScreenCSD/volume.tsv") %>% #, "ExtraCSD2") %>% 
  map_dfr(parse_vol_data, .id = "src")

# Or, screening_gcmc %>% inner_join(ccdc_predicted, by="id") %$% parity_plot(g.L, y_pred)
screening_top_performance <- 
  ccdc_h2_grids %>%
  filter(id %in% screening_gcmc$id) %>%
  filter(id %in% ccdc_top500$id) %>%  # In the paper, we'll only be looking at the top 500 MOFs
  eval_test_grid(trained_mod, ., default_binspec, mutate(screening_gcmc, y_act=g.L))
screening_top_performance
screening_accuracy <- 
  screening_gcmc %>% 
  mutate(y_act = g.L) %>% 
  filter(id %in% ccdc_top500$id) %>% 
  inner_join(ccdc_predicted, by="id") %>% 
  mutate(y_err = y_pred - y_act) %>% 
  arrange(desc(abs(y_err)))
View(screening_accuracy)
# Instead of a parity plot (which is misleading), maybe we should just evaluate the overall residuals
hist(screening_accuracy$y_err, xlab="Overprediction")
nrow(filter(screening_accuracy, y_act > 46)) / nrow(filter(screening_accuracy, y_pred > 46))
(screening_accuracy %>% 
  ggplot(aes(y_act, y_pred, id=id)) +
  geom_point() +
  parity_line +
  coord_fixed()
  ) %>% 
  ggplotly

# Finally, let's stratify by dimensionality using previous code deleted in 29a74040
# Check the MOF framework dimensionality from Zeo++.
ccdc_dimensionality <- read_tsv(
  "BigData/quest/DimsCCDC/all_dimensionality.tsv",
  col_types="ciiiiii"
  )
ccdc_dimensionality %$% expect_equal(segments, frameworks + molecules)
ccdc_dimensionality %$% expect_equal(frameworks, f1d + f2d + f3d)
p_top_ccdc_by_dim <- 
  screening_accuracy %>% 
  left_join(ccdc_dimensionality, by="id") %>% 
  mutate(has_2d = (f2d>0)) %>% 
  mutate(has_3d = (f3d>0)) %>% 
  mutate(dim_tag = ifelse(has_2d, "2D", "")) %>% 
  mutate(dim_tag = ifelse(has_3d, "3D", dim_tag)) %>% 
  mutate(dim_tag = ifelse(dim_tag=="", "No 2D or 3D", dim_tag)) %>% 
  ggplot(aes(y_act, y_pred, id=id)) +
  geom_point() + parity_line +
  coord_fixed() +
  facet_wrap(~dim_tag) +
  ggtitle("Dimensionality of framework")
ggplotly(p_top_ccdc_by_dim)
p_top_ccdc_by_dim %>% save_si_fig("top_ccdc_by_dims.png", base_aspect_ratio=1.5)

p_top_ccdc_by_dim$data %>% 
  filter(has_3d) %>% 
  nrow %>%
  paste("Number of 3D CIFs:", .) %>% 
  print
p_top_ccdc_by_dim$data %>% 
  filter(has_3d) %>% 
  select(id, y_act, y_pred) %>% 
  arrange(desc(y_act)) %>% 
  rownames_to_column("Rank")


# Note: GUNFAW01 is one of the top structures in Thornton 2017 but has poor performance (6 g/L) in the RR
# due to a bulky Ru component in the pore (counterion, or possibly missed solvent?).
# Some of the other structures were noted the same, although many of the top candidates have long rod structures.


# Another quick test: how consistent are my GCMC simulations vs. Scotty's?
screening_gcmc %>% 
  rename(new.g.L = g.L) %>%
  inner_join(ccdc_gcmc, by="id") %>% 
  rename(old.g.L = g.L) %>%
  select(id, old.g.L, new.g.L) %>% 
  mutate(discrepancy = abs(new.g.L - old.g.L)) %>% 
  arrange(desc(discrepancy))

```



## Supporting Information for manuscript

This section is still largely TODO but at least can be done in part for some of the more important figures.

### Outline
First, some random figures that haven't been placed elsewhere for the SI yet.

```{r unsorted_si_figures}
# * See base case analysis above for plain textural properties.  Understand the limitations of MLR on CH4 (vs. H2).  Has this sort of analysis been done before, except for the ANNs?
# * What to do about accessible vs. non-accessible properties?  Just use the hMOFs verbatim (plus density)?  Do a combined void fraction?

```

### Database distributions

```{r si_distr}
# Geometric property distributions for the databases
p_geom_distr <- 
  textural_props %>% 
  select(-id, -h2.deliv.77) %>%
  rename(  # plotmath is very messy...
    `atop('Gravimetric surface', 'area'~(m^2/g))` = gsa,
    #`H2 deliverable\ncapacity (g/L)` = h2.deliv.77,
    `atop('Largest cavity', 'diameter'~(ring(A)))` = lcd,
    `'Void fraction'` = vf,
    `atop('Volumetric surface', 'area'~(m^2/cm^3))` = vsa
    ) %>% 
  gather("property", "value", -db) %>% 
  ggplot(aes(value)) +  # Trying to use ..density.. here results in strange behavior
  geom_histogram(bins=30) +
  # Idea related to https://stackoverflow.com/questions/11335836/increase-number-of-axis-ticks
  scale_x_continuous(breaks=scales::pretty_breaks(n=2)) +
  facet_grid(db ~ property, scales = "free", labeller = label_parsed) +
  background_grid()
p_geom_distr %>% save_si_fig("geom_distr.png", base_aspect_ratio=1.6)
p_geom_distr

p_y_distr <- 
  tobacco_data %>% 
  mutate(y_act = fh.h2.g.L.100.77 - fh.h2.g.L.2.77) %>% 
  select(g.L = y_act) %>% 
  bind_rows(
    ToBaCCo = .,
    hMOFs = select(gcmc_data, g.L),
    .id = "db"
    ) %>% 
  filter(g.L >= 0) %>% 
  ggplot(aes(g.L, ..density..)) +
  geom_histogram(bins=30) +
  facet_wrap(~db) +
  xlab("Hydrogen deliverable capacity, 77 K, 100 bar - 2 bar") 
p_y_distr %>% save_si_fig("y_distr.png", base_aspect_ratio=1.6)
p_y_distr

p_x_distr_hmof <- plot_avg_with_distr(hmof_h2_grid, default_binspec, print_violin=TRUE)
p_x_distr_hmof
p_x_distr_tob <- plot_avg_with_distr(grids_h2, default_binspec, print_violin=TRUE)
p_x_distr_tob
plot_grid(
  p_x_distr_hmof + coord_cartesian(xlim = c(-15, 2)),
  p_x_distr_tob + coord_cartesian(xlim = c(-15, 2)),
  ncol=1,
  labels=default_subfig_labels, label_size=12
  ) %>%
  save_si_fig("x_distr.png", nrow = 2, base_aspect_ratio=1.6)

# How many samples are there for each bin in the training data?
# Answer: LASSO takes care of this automatically.
# Justify the model using the regu_coef.tex table (showing -13 to -11 kJ/mol is set to zero.)
# Also consider adding a column with the number of nonzero training points.
hmof_hist_sets$training %>%
  stepped_hist_spec(default_binspec) %>%
  select(-id) %>%
  filter(!(near(metric, 0))) %>%
  group_by(bin) %>% summarize(nsample = n()) %>%
  inner_join(bin_loc_from_spec(default_binspec), by="bin")

# In general, there should be an inverse relationship between void fraction and the infinite bin.
# The match will not be exact because the energy cutoffs are rather different.
p_vf_vs_inf <- 
  hmof_h2_grid %>% 
  stepped_hist_spec(default_binspec) %>% 
  filter(bin == "Inf") %>% 
  rename(`Inf bin` = metric) %>% 
  left_join(gcmc_data, by="id") %>%
  ggplot(aes(void.frac, `Inf bin`)) +
  geom_point(alpha=0.5) +
  xlim(0, 1) + ylim(0, 1) +
  xlab("Void fraction") + ylab("Repulsive bin")
p_vf_vs_inf
save_si_fig(p_vf_vs_inf, "vf_vs_inf.png")

```


### Considerations for molecular simulation

```{r si_simulation}
tobacco_data %>% 
  {list(
    `2 bar, 77 K` = ggplot(., aes(nofh.h2.g.L.2.77, fh.h2.g.L.2.77)),
    `100 bar, 77 K` = ggplot(., aes(lj.h2.g.L.100.77, fh.h2.g.L.100.77))
    )} %>% 
  map(
    ~ .x +
    geom_point() +
    coord_fixed(xlim = c(0, 70), y=c(0, 70)) +
    xlab("Lennard-Jones potential only") +
    ylab("With Feynman-Hibbs") +
    parity_line
    #annotate("text", x=10, y=50, label=names(.x))
    ) %>% 
  map2(
    .,
    names(.),
    function(x, y) {
      x + annotate("text", x=10, y=60, label=y)
    }
  ) %>% 
  {plot_grid(
    .[[1]], .[[2]],
    ncol=2,
    labels=default_subfig_labels, label_size=12
  )} %>% 
  save_si_fig("fh_correction.png", ncol=2)

```


### Model performance
```{r si_performance}
# Residuals of hMOFs and ToBaCCo
plot_resid_vs_act <- function(df) {
  ggplot(df, aes(y_act, y_act-y_pred)) +
    geom_point() +
    geom_hline(yintercept = 0) +
    xlab("y") + ylab(expression('Residuals '~y-hat(y)))
}
plot_grid(
  hmof_partitioned_mod$plots$resid_normality,
  p_tob_mod$plots$resid_normality,
  plot_resid_vs_act(hmof_partitioned_mod$pred_df),
  plot_resid_vs_act(p_tob_mod$pred_df),
  ncol=2, nrow=2,
  labels=default_subfig_labels, label_size=12
  ) %>% 
  save_si_fig("residuals.png", ncol=2, nrow=2)

# Ranking of hMOF and ToBaCCo
plot_grid(
  hmof_partitioned_mod$plots$test_ranking,
  p_tob_mod$plots$test_ranking,
  ncol=2,
  labels=default_subfig_labels, label_size=12
  ) %>% 
  save_si_fig("ranking.png", ncol=2)

# Error breakdown by topology
p_err_topology <- 
  p_tob_mod$pred_df %>% 
  left_join(tobacco_data, by="id") %>% 
  ggplot(aes(y_act, y_pred)) + 
  geom_point() + parity_line +
  facet_wrap(~topology) +
  coord_fixed() +
  scale_x_continuous(breaks=c(0,40)) +
  #scale_y_continuous(breaks=scales::pretty_breaks(n=2)) +
  scale_y_continuous(breaks=c(0, 40)) +
  xlab("'Actual' uptake (GCMC simulations)") +
  ylab("Predicted uptake (ridge regression)")
p_err_topology %>% save_si_fig("err_by_topology.png", bheight=5)

```

### Model regularization strategies
```{r si_regularization}
# Lambda plot from glmnet package.
# Viewing the source code with `plot.cv.glmnet` is very informative.
# See also an online vignette https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html#lin
set_li <- function(x, label, value) {
  # Sets the value of a labelled list item then returns the full list.
  # Pipe-friendly assignment for lists.  Use quotes around the label title
  x[[label]] <- value
  x
}
trained_mod$cv_for_lambda %>% 
  set_li("lambda.1se", NA) %>%  # Remove the 1SE line for clarity
  set_li(., "nzero", rep("", length(.$nzero))) %>%  # Hide the number of variables used
  plot
#recordPlot() %>%  # Thanks, https://github.com/wilkelab/cowplot/issues/69
#  plot_to_gtable() %>%  # requires gridGraphics
#  save_si_fig("lambda.png")
# This works, but it'll be easier to figure out labels, aspect, etc. if we just replot it.
# After all, we have the plot.cv.glmnet source code easily available.
p_si_lambda_lambdamin <- trained_mod$cv_for_lambda$lambda.min
p_si_lambda_lambda1se <- trained_mod$cv_for_lambda$lambda.1se
p_si_lambda <- 
  trained_mod$cv_for_lambda %$% 
  qplot(log(lambda), cvm) +
  xlab("log(lambda)") +
  ylab("Mean-Squared Error") +
  geom_vline(xintercept=log(p_si_lambda_lambdamin), linetype="dotted") +
  geom_vline(xintercept=log(p_si_lambda_lambda1se), linetype="dashed")
p_si_lambda
p_si_lambda %>% save_si_fig("lambda.png")


# Combining LASSO, MLR, and ridge in a single figure
save_fig_table <- function(df, filename, digits=2, col_header = FALSE, parent_dir=default_fig_dir) {
  # Writes a table to a Latex file which can be read with \input
  # https://www.r-bloggers.com/exporting-r-tables-in-latex/
  append_data <- FALSE
  if (is.character(col_header) & length(col_header) == 1) {
    cat(col_header, file = file.path(parent_dir, filename))
    col_header <- FALSE
    append_data <- TRUE
  }
  df %>% 
    as.data.frame() %>%  # tibbles add a strange header to the file
    format(digits = digits) %>%  # Digits is only a suggestion
    write.table(
      file.path(parent_dir, filename),
      quote = FALSE,
      row.names = FALSE,
      col.names = col_header,
      eol="\\\\\n",
      sep=" & ",
      append = append_data
      )
}

save_fig_table_with_colnames <- function(df, filename, ...) {
  save_fig_table(
    df,
    filename,
    col_header=paste0(paste(colnames(df), collapse = " & "), "\\\\\n\\hline\n"),
    ...
    )
}

trained_model_regu <- list(
  Ridge = run_model_on_partitions(hmof_hist_sets, hmof_y_to_join, default_binspec, 0, db_name = "hMOFs"),
  LASSO = run_model_on_partitions(hmof_hist_sets, hmof_y_to_join, default_binspec, 1, db_name = "hMOFs"),
  MLR = run_model_on_partitions(hmof_hist_sets, hmof_y_to_join, default_binspec, alpha=1, lambda=0, thresh=1e-16, db_name = "hMOFs")
)

trained_model_regu %>% 
  #set_li("Ridge", NULL) %>%  # We only need to plot LASSO and MLR here
  map2(., names(.), function(x,y) {x$plots$parity_testing + annotate("text", x=45, y=20, label=y, size=6)}) %>% 
  {do.call(  # For future reference, purrr:invoke is probably what I was looking for as a wrapper
    plot_grid,
    c(., list(  # https://stackoverflow.com/questions/25962605/how-to-add-more-arguments-of-a-function-in-do-call-in-r
      ncol=2, nrow=2,
      labels=default_subfig_labels, label_size=12
      )
    )
    )} %>% 
  save_si_fig("regu_parity.png", ncol=2, nrow=2)

trained_model_regu %>% 
  map_dfr(~ coef_tbl(.x$trained_mod$mod), .id="method") %>% 
  spread(method, beta) %>% 
  left_join(bin_loc_from_spec(default_binspec), by="bin") %>% 
  select(-bin) %>% 
  mutate(Bin=paste(lower, "to", upper, "kJ/mol")) %>% 
  mutate(Bin=ifelse(is.na(lower), "(Intercept)", Bin)) %>% 
  arrange(lower) %>% 
  select(Bin, Ridge, LASSO, MLR) %>% 
  save_fig_table_with_colnames("regu_coef.tex")

trained_model_regu %>%  # What are the lambda/alpha for the models?
  map_dfr(function(x) {list(lambda=x$trained_mod$lambda, alpha=x$trained_mod$alpha)}, .id="method")
  # If this is useful, gather then separate to add it to the previous DF, or a separate tex file.


# Saving tables of other model coefficients for model formulation analysis
p_beta_diff_p$layers[[2]]$data %>% 
  mutate(beta = beta * BETA_H2_SCALING) %>%  # undo scaling from `overlay_cat_betas`
  select(lower, upper, cat, beta) %>% 
  spread(cat, beta) %>% 
  select(lower, upper, `2 bar`, `100 bar`) %>% 
  save_fig_table_with_colnames("coef_p.tex")

p_beta_diff_t$layers[[2]]$data %>% 
  mutate(beta = beta * BETA_H2_SCALING) %>%  # undo scaling from `overlay_cat_betas`
  select(lower, upper, cat, beta) %>% 
  spread(cat, beta) %>% 
  select(lower, upper, `77 K`, `160 K`) %>% 
  save_fig_table_with_colnames("coef_t.tex")

p_beta_ch4$layers[[2]]$data %>% 
  mutate(beta = beta * BETA_CH4_SCALING) %>%  # undo scaling from `overlay_cat_betas`
  select(lower, upper, cat, beta) %>% 
  spread(cat, beta) %>% 
  select(lower, upper, `5.8 bar`, `65 bar`) %>% 
  save_fig_table_with_colnames("coef_ch4.tex")

```

### Consistency between different datasets
hMOF vs. ToBaCCo, etc.

```{r si_consistency}
# Comparison of beta coefficients from ridge regression for the two databases.
# This code will have a similar structure to plotting multiple temperatures or pressures.
p_coef_compare <- 
  list(`hMOF` = trained_mod$mod, `ToBaCCo` = p_tob_mod$trained_mod$mod) %>% 
  map_dfr(coef_tbl, .id="cat") %>%
  overlay_cat_betas(base_hist, ., default_binspec) +
  theme(legend.position=c(0, 0.2), legend.direction="horizontal")
p_coef_compare
p_coef_compare %>% save_si_fig("coef_compare.png", base_aspect_ratio = 1.5)

p_coef_compare$layers[[2]]$data %>% 
  mutate(beta = beta * BETA_H2_SCALING) %>%  # undo scaling from `overlay_cat_betas`
  select(lower, upper, cat, beta) %>% 
  spread(cat, beta) %>% 
  select(lower, upper, hMOF, ToBaCCo) %>% 
  save_fig_table("coef_hmof_vs_tobacco.tex")

# TODO MORE

```




## TODO notes from meetings
### General
* Finish work on textural properties!  Particularly ToBaCCo might be interesting.  Does the model transfer to the CCDC dataset?
* Consider redoing the isotherms for the two case study MOFs (and possibly pick more unique MOFs, since I'll need to calculate finer grids, anyway.)

### More simulations/grids
* Run calculations of the top CCDC candidates and confirm results. (get from mateo:ScreenCSD and ExtraCSD2)
  * Update analysis of specific top CCDC candidates
  * Reviewers will like seeing detailed analysis of the top candidates (and possibly screenshots/details of the top ~10 in the SI)
* Grid convergence testing!!!

### Model form and applicability
* Recalculate the beta robustness figure (cached as an Rds file.  Should figure out if missing energy bins are caused by the new code, hMOF pecularity, or other.  Maybe it's how "low variance" is calculated, which doesn't work for small bins?)
  * Inconclusive, even without the `bin_loc_from_spec` line.  See: `hmof_hist_sets$training %>% stepped_hist_spec(c(from=-20, to=0, step=0.25, width=0.25), align_bins = "downward") %>% select(-id) %>% filter(!(near(metric, 0))) %>% group_by(bin) %>% summarize(nsample = n()) %>% inner_join(bin_loc_from_spec(c(from=-20, to=0, step=0.25, width=0.25), align_bins="downward"), by="bin")`

### Q2-type analysis
* Make a few parity plots from the Q2/binning analysis.  Is the good prediction consistent across histogram parameters?  How about for ToBaCCo, since it's likely more sensitive?
* Try to break Q2=0 with small n.  How low can we go?  Is 1000 samples way too many for this?
* Recalculate Q2 once we relax the penalty term to be lower.  Beyond RMSE, etc., how does Q2 vary for the models and levels of regularization along that plot?


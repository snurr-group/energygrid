---
title: "Generating figures for the manuscript"
author: "Ben Bucior"
date: "December 20, 2017"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
```

```{r setup_data, include=FALSE}
# Has to be run in a separate block as above
source("Notebooks/setup_data.R")
library(plotly)
```

```{r setup_figs}
# Setup figure parameters
library(cowplot)
# See [intro documentation](https://cran.r-project.org/web/packages/cowplot/vignettes/introduction.html) and [vignette](https://cran.r-project.org/web/packages/cowplot/vignettes/plot_grid.html)
# Per [RSC guidelines](http://www.rsc.org/journals-books-databases/journal-authors-reviewers/submit-your-article/#figures-graphics-images),
# figures should be single column (8.3cm) or double column (17.1cm) and no longer than 23.3cm.
# For final submission, they like 600 dpi TIFF files.  Before then, let's use smaller figs.
default_dpi <- 300
theme_set(theme_cowplot(font_size = 10))
default_fig_dir <- "Figs"
default_subfig_labels <- paste0("(", letters, ")")

mkdirs(default_fig_dir)
save_ben_fig <- function(p, filename, parent_dir = default_fig_dir, ...) {
  save_plot(
    file.path(parent_dir, filename),
    p,
    base_width = 8.3 / 2.54,  # RSC width in inches
    base_height = NULL,  # calculate from base_aspect_ratio and the width
    dpi = default_dpi,
    ...
    )
}
make_draft <- function(p, msg="DRAFT!") {
  # Derived from cowplot intro
  ggdraw(p) +
    draw_label(msg, angle = 45, size = 72, alpha = .2)
}
save_si_fig <- function(p, filename, parent_dir = default_fig_dir, bheight = 3.3, bwidth = NULL, ...) {
  save_plot(
    file.path(parent_dir, filename),
    p,
    base_width = bwidth,  # defaults to NULL (automatic based on the aspect ratio)
    base_height = bheight,  # Height in inches
    dpi = default_dpi,
    ...
    )
}

# Example:
# hmof_partitioned_mod$plots %$% plot_grid(parity_training, make_draft(parity_testing), ncol=1, labels=default_subfig_labels, label_size=12) %>% save_ben_fig("test.png", nrow = 2)
```

## Figures for manuscript: main text

Recreate (and export) figures in one block.  Possibly will be externalized into a separate script later.

```{r make_figures}
# Figures on adsorption strength (conceptual) and ML workflow (to update, but external)
# (likely generated within other software)

# Coefficients for ridge regression model
hmof_partitioned_mod <- run_model_on_partitions(hmof_hist_sets, hmof_y_to_join, default_binspec, 0)
trained_mod <- hmof_partitioned_mod$trained_mod
base_hist <- hmof_h2_grid %>% 
  filter(id == 71) %>% 
  plot_hist_bins(default_binspec)
p_beta_orig <- base_hist %>% overlay_cat_betas(coef_tbl(trained_mod$mod), default_binspec)
p_beta_orig

# Beta coefficients for different pressures and temperatures
# For help on NSE in dplyr, see vignette("programming")
library(rlang)  # see also https://github.com/tidyverse/rlang/issues/116
mutate_col_to_gL <- function(df, newcol) {
  mutate(df, g.L = !!sym(newcol))
}
## Previously used for the CH4 plots, but no reason not to adapt it for T and P of H2
p_beta_diff_p <- 
  list(`100 bar` = "va100bar", `2 bar` = "va2bar") %>% 
  map(mutate_col_to_gL, df = gcmc_data) %>%
  map(function(x) run_model_on_partitions(hmof_hist_sets, x, default_binspec, 0)) %>% 
  map(function(x) x$trained_mod$mod) %>% 
  map_dfr(coef_tbl, .id="cat") %>% 
  overlay_cat_betas(base_hist, ., default_binspec)
p_2bar_grids <- hmof_h2_grid %>% filter(id %in% p_2bar_data$id)
p_2bar_sets <- partition_data_subsets(p_2bar_grids, p_2bar_data, DATA_SPLIT)
p_beta_diff_t <- 
  list(`160 K` = "h2.g.L.2.160", `77 K` = "va2bar") %>% 
  map(mutate_col_to_gL, df = p_2bar_data) %>%
  map(function(x) run_model_on_partitions(p_2bar_sets, x, default_binspec, 0)) %>% 
  map(function(x) x$trained_mod$mod) %>% 
  map_dfr(coef_tbl, .id="cat") %>% 
  overlay_cat_betas(base_hist, ., default_binspec)
# Generate the plots
plot_grid(
  p_beta_orig,
  p_beta_diff_p + theme(legend.position=c(0, 0.2), legend.direction="horizontal"),
  make_draft(p_beta_diff_t + theme(legend.position=c(0, 0.2), legend.direction="horizontal")),
  ncol=1,
  #align = "v",
  labels=default_subfig_labels, label_size=12
  ) %>%
  save_ben_fig("betas.png", nrow = 3, base_aspect_ratio = 1.5)


# Model fit for hMOF ridge regression mdoel
print(hmof_partitioned_mod)
hmof_partitioned_mod$plots %$%
plot_grid(
  parity_training,
  parity_testing,
  ncol = 1,
  labels=default_subfig_labels, label_size=12
  ) %>% 
  save_ben_fig("parity.png", nrow = 2)

# Print stats for other databases, including fitting the ToBaCCo data to itself
# tob_y_to_join and tob_hist_sets are defined in setup_data.R
p_tob_mod <- run_model_on_partitions(tob_hist_sets, tob_y_to_join, default_binspec, 0)
p_tob_mod
# ...and using the hMOF-trained model directly on the ToBaCCo database
p_tob_from_hmof <- 
  tobacco_data %>% 
  mutate(y_act = fh.h2.g.L.100.77 - fh.h2.g.L.2.77) %>% 
  eval_test_grid(hmof_partitioned_mod$trained_mod, tob_hist_sets$testing, default_binspec, .)
# CCDC applicability, etc.
print("Note: revised below in another code block")  # FIXME: revise it directly here, then generate the other code block
p_ccdc_random <- 
  ccdc_h2_grids %>% 
  filter(id %in% ccdc_gcmc$id) %>% 
  eval_test_grid(trained_mod, ., default_binspec, mutate(ccdc_gcmc, y_act=g.L))
# Generate the (large) figure for model generality
p_tob_mod$plots %$%
  plot_grid(
    parity_training,
    parity_testing,
    p_tob_from_hmof$plots$parity_testing,
    make_draft(p_ccdc_random$plots$parity_testing),
    ncol = 2,
    labels=default_subfig_labels, label_size=12
    ) %>% 
  save_ben_fig("general_parity.png", nrow = 2, ncol = 2)



# Robustness to histogram binning strategy
hyper_tuned_hist <- read_rds("BigData/Robj/hyper_tuned.Rds")  # FIXME: This will need to be regenerated
plot_robustness_bin_gap <- 0.05
plot_robustness_beta_max <- 5
p_robust <- 
  hyper_tuned_hist %>% 
  mutate(beta = ifelse(beta > plot_robustness_beta_max, plot_robustness_beta_max, beta)) %>% 
  mutate(beta = ifelse(beta < -plot_robustness_beta_max, -plot_robustness_beta_max, beta)) %>% 
  mutate(lower = lower + plot_robustness_bin_gap, upper = upper - plot_robustness_bin_gap) %>% 
  ggplot(aes(
    x = binwidth,
    ymin = lower,
    ymax = upper,
    color = beta
  )) +
  geom_linerange(size=2) +
  coord_flip() +
  scale_color_gradientn(
    colors = c("red", "darkgray", "blue"),
    limits = c(-plot_robustness_beta_max, plot_robustness_beta_max),
    breaks = c(-plot_robustness_beta_max, 0, plot_robustness_beta_max),
    labels = c(paste0(-plot_robustness_beta_max,"-"), "0", paste0(plot_robustness_beta_max,"+")),
    name=expression(beta[ridge])
    ) +
  labs(
    y = "Energy (kJ/mol)",
    x = "Width of histogram bins (kJ/mol)"
  )
p_robust
save_ben_fig(p_robust, "beta_robustness.png", base_aspect_ratio=1.3)


# Models based on textural properties
# TODO: add density to the MOFs.  We could also consider DPD, though that's only based on PSD
# TODO: all of the "good" models so far have been based on methane.  Can we reproduce the good predictivity for CH4 using MLR?  Maybe the problem is like hydrogen storage, where high P is predicted by Chahine's rule
# Serves as a baseline for how well the energy histogram is working.
# Selected properties based on a quick literature review of ML:
# We should use rho, VF, VSA/GSA, and potentially LCD or other pore diameters.
# Cory Simon, EES 2015, 1190-1199: Density, VF, largest included sphere, AVSA
# Fernandez, JPCC 2013, 7681-7689: DPD, VF, GSA (and VSA)
# Pardakhti, ACS Comb Sci 2017, 7681-7689: VF, GSA, density, DPD, LCD, Interp. cap, Cat nets
# Plus chemical properties: element counts, metal type, degree of saturation, metallic %, ratios of atom types
# Thornton, Chem Mater 2017, 2844-2854: VF, density, adsorption energy (kJ/mol), pore diameter, GSA, VSA
# First, prepare the input data
textural_props <- 
  gcmc_data %>% 
  mutate(h2.deliv.77 = va100bar - va2bar) %>% 
  select(id, vf=void.frac, lcd, gsa=surf.area..mass., vsa=surf.area..vol., h2.deliv.77) %>% 
  mutate(id = str_c("h", id))
textural_props <- 
  tobacco_data %>% 
  mutate(h2.deliv.77 = fh.h2.g.L.100.77 - fh.h2.g.L.2.77) %>% 
  select(id, vf, lcd, gsa, vsa, h2.deliv.77) %>% 
  bind_rows(hMOF = textural_props, ToBaCCo = ., .id = "db") %>% 
  na.omit
# Run ridge regression models and generate parity plots in the same style as the energy grid method
textural_hmofs <- 
  textural_props %>% 
  filter(db == "hMOF") %>% 
  select(-db)
textural_training_rows <- sample(nrow(textural_hmofs), 1000)
textural_mod <- 
  textural_hmofs %>% 
  .[textural_training_rows,] %>% 
  select(-id) %>% 
  {fit_glmnet(select(., -h2.deliv.77), .$h2.deliv.77)}
# (will probably be the same fit_glmnet function)
textural_pred <- 
  textural_hmofs %>% 
  .[-textural_training_rows,] %>% 
  select(-id, -h2.deliv.77) %>% 
  pred_glmnet(textural_mod, .)
textural_act <- textural_hmofs[-textural_training_rows, "h2.deliv.77"]
parity_plot(textural_act, textural_pred, alpha=0.1)
postResample(pred=textural_pred, obs=textural_act)
textural_mod$lambda


# Methane predictions
p_ch4_vol <- p_2bar_data %>% 
  mutate(g.L = ch4.cm3.cm3.65.298 - ch4.cm3.cm3.5_8.298) %>% 
  run_model_on_partitions(p_ch4_sets, ., ch4_binspec, 0)
p_ch4_vol$plots$parity_full +
  scale_x_continuous(limits = c(0,250)) +
  scale_y_continuous(limits = c(0,250))
ch4_base_hist <- p_ch4_grids %>% 
  filter(dirname == "hMOF-71") %>%  # Using the same MOF as the sample H2 histogram
  plot_hist_bins(ch4_binspec)
p_beta_ch4 <- 
  list(`5.8 bar` = "ch4.cm3.cm3.5_8.298", `65 bar` = "ch4.cm3.cm3.65.298") %>% 
  map(mutate_col_to_gL, df=p_2bar_data) %>%
  map(function(x) run_model_on_partitions(p_ch4_sets, x, ch4_binspec, 0)) %>% 
  map(function(x) x$trained_mod$mod) %>% 
  map_dfr(coef_tbl, .id="cat") %>% 
  overlay_cat_betas(ch4_base_hist, ., ch4_binspec, scaling = 20.0)

p_ch4_vol$plots %$%
  plot_grid(
    parity_training +
      scale_x_continuous(limits = c(0,250)) +
      scale_y_continuous(limits = c(0,250)),
    parity_testing +
      scale_x_continuous(limits = c(0,250)) +
      scale_y_continuous(limits = c(0,250)),
    p_beta_ch4 + theme(legend.position=c(0, 0.2), legend.direction="horizontal"),
    #make_draft(NULL, "TODO"),
    ncol = 1,
    rel_heights = c(1, 1, 1.1/1.5),
    labels=default_subfig_labels, label_size=12
    ) %>% 
  #save_ben_fig("ch4_plots.png", nrow = 2, ncol = 2)
  save_ben_fig("ch4_plots.png", nrow = 3, ncol = 1)

```


## Supporting Information for manuscript

This section is still largely TODO but at least can be done in part for some of the more important figures.

### Outline
First, some random figures that haven't been placed elsewhere for the SI yet.

```{r unsorted_si_figures}


```

### Database distributions

```{r si_distr}
# Geometric property distributions for the databases
p_geom_distr <- 
  textural_props %>% 
  select(-id, -h2.deliv.77) %>%
  rename(  # plotmath is very messy...
    `atop('Gravimetric surface', 'area'~(m^2/g))` = gsa,
    #`H2 deliverable\ncapacity (g/L)` = h2.deliv.77,
    `atop('Largest cavity', 'diameter'~(ring(A)))` = lcd,
    `'Void fraction'` = vf,
    `atop('Volumetric surface', 'area'~(m^2/cm^3))` = vsa
    ) %>% 
  gather("property", "value", -db) %>% 
  ggplot(aes(value)) +  # Trying to use ..density.. here results in strange behavior
  geom_histogram(bins=30) +
  # Idea related to https://stackoverflow.com/questions/11335836/increase-number-of-axis-ticks
  scale_x_continuous(breaks=scales::pretty_breaks(n=2)) +
  facet_grid(db ~ property, scales = "free", labeller = label_parsed) +
  background_grid()
p_geom_distr %>% save_si_fig("geom_distr.png", base_aspect_ratio=1.6)
p_geom_distr

p_y_distr <- 
  tobacco_data %>% 
  mutate(y_act = fh.h2.g.L.100.77 - fh.h2.g.L.2.77) %>% 
  select(g.L = y_act) %>% 
  bind_rows(
    ToBaCCo = .,
    hMOFs = select(gcmc_data, g.L),
    .id = "db"
    ) %>% 
  filter(g.L >= 0) %>% 
  ggplot(aes(g.L, ..density..)) +
  geom_histogram(bins=30) +
  facet_wrap(~db) +
  xlab("Hydrogen deliverable capacity, 77 K, 2 bar - 100 bar") 
p_y_distr %>% save_si_fig("y_distr.png", base_aspect_ratio=1.6)
p_y_distr

plot_x_distr <- function(egrid, binspec, lower_cutoff=-Inf) {
  egrid %>% 
    stepped_hist_spec(binspec) %>% 
    spread(key=bin, value=metric) %>% 
    select(-id) %>% 
    #standardize(stdmod, .) %>% 
    gather(key="bin", value="value") %>% 
    left_join(bin_loc_from_spec(binspec), by="bin") %>% 
    filter(lower >= lower_cutoff) %>% 
    #gather(key="bin", value="value") %>% 
    #mutate(binlab = factor(paste("Bin from", lower, "to", upper, "kJ/mol"), ordered=TRUE)) %>% 
    mutate(binlab = paste("Bin from", lower, "to", upper, "kJ/mol")) %>% 
    # Use an ordered factor (with specified levels) to order by numeric energy instead of binlab char
    arrange(lower) %>% 
    mutate(faclab = factor(binlab, levels=unique(binlab), ordered=TRUE)) %>%
    ggplot(aes(value)) +
    geom_histogram(bins = 30) +
    facet_wrap(~faclab, scales="free") +
    xlab("Value of histogram bin (fraction of unit cell)") +
    ylab("Number of MOFs") +
    scale_x_continuous(breaks=scales::pretty_breaks(n=2))
    #theme(text = element_text(size = 8))
}
p_x_distr_hmof <- plot_x_distr(hmof_h2_grid, default_binspec, -7)
p_x_distr_hmof
p_x_distr_tob <- plot_x_distr(grids_h2, default_binspec, -7)
p_x_distr_tob
plot_grid(
  p_x_distr_hmof,
  p_x_distr_tob,
  ncol=1,
  labels=default_subfig_labels, label_size=12
  ) %>%
  save_si_fig("x_distr.png", nrow = 2, base_aspect_ratio=1.6)

# In general, there should be an inverse relationship between void fraction and the infinite bin.
# The match will not be exact because the energy cutoffs are rather different.
p_vf_vs_inf <- 
  hmof_h2_grid %>% 
  stepped_hist_spec(default_binspec) %>% 
  filter(bin == "Inf") %>% 
  rename(`Inf bin` = metric) %>% 
  left_join(gcmc_data, by="id") %>%
  ggplot(aes(void.frac, `Inf bin`)) +
  geom_point(alpha=0.5)
p_vf_vs_inf
save_si_fig(p_vf_vs_inf, "vf_vs_inf.png")

```


### Considerations for molecular simulation

```{r si_simulation}
# Comparison between CH4 and H2 adsorption in the ToBaCCo MOFs (consider redoing with hMOF data)
tidy_ch4_vs_h2 <-
  gcmc_data %>% 
  rename(h2.g.L.2.77 = va2bar, h2.g.L.100.77 = va100bar) %>% 
  gather(key, uptake, starts_with("h2.g.L."), starts_with("ch4.cm3.cm3.")) %>% 
  #tobacco_data %>% 
  #gather(key, uptake, starts_with("y.ch4.v.v."), starts_with("fh.h2.g.L.")) %>% 
  select(id, key, uptake) %>% 
  separate(key, c("gas", "unit1", "unit2", "pressure", "temperature"), sep="\\.") %>% 
  #separate(key, c("user", "gas", "unit1", "unit2", "pressure", "temperature")) %>% 
  unite("units", paste0("unit", 1:2), sep=".")
p_si_ch4_vs_h2 <- 
  tidy_ch4_vs_h2 %>% 
  na.omit %>% 
  select(-units) %>% 
  mutate(pressure = str_replace(pressure, "_", ".")) %>% 
  mutate(pressure = paste(pressure, "bar"), temperature = paste(temperature, "K")) %>% 
  #select(-units, -user) %>% 
  {inner_join(filter(., gas=="ch4"), filter(., gas=="h2"), by="id", suffix=(c(".ch4", ".h2")))} %>% 
  left_join(select(gcmc_data, id, void.frac), by="id") %>% 
  ggplot(aes(uptake.h2, uptake.ch4, col=void.frac)) +
  geom_point() +
  facet_grid(temperature.ch4+pressure.ch4 ~ temperature.h2+pressure.h2, scales="free_x") +
  scale_x_continuous(breaks=scales::pretty_breaks(n=2)) +
  xlab(expression(H[2]~uptake~(g/L))) +
  ylab(expression(CH[4]~uptake~(cm^3/cm^3))) +
  labs(color="Void\nfraction")
p_si_ch4_vs_h2  # not sure what happened to this figure.  More investigation required
p_si_ch4_vs_h2 %>% save_si_fig("ch4_vs_h2_ads.png", base_aspect_ratio = 1.6)

tobacco_data %>% 
  {list(
    `2 bar, 77 K` = ggplot(., aes(nofh.h2.g.L.2.77, fh.h2.g.L.2.77)),
    `100 bar, 77 K` = ggplot(., aes(lj.h2.g.L.100.77, fh.h2.g.L.100.77))
    )} %>% 
  map(
    ~ .x +
    geom_point() +
    coord_fixed(xlim = c(0, 70), y=c(0, 70)) +
    xlab("Lennard-Jones potential only") +
    ylab("With Feynman-Hibbs") +
    parity_line
    #annotate("text", x=10, y=50, label=names(.x))
    ) %>% 
  map2(
    .,
    names(.),
    function(x, y) {
      x + annotate("text", x=10, y=60, label=y)
    }
  ) %>% 
  {plot_grid(
    .[[1]], .[[2]],
    ncol=2,
    labels=default_subfig_labels, label_size=12
  )} %>% 
  save_si_fig("fh_correction.png", ncol=2)

```


### Model performance
```{r si_performance}
# Residuals of hMOFs and ToBaCCo
plot_resid_vs_act <- function(df) {
  ggplot(df, aes(y_act, y_act-y_pred)) +
    geom_point() +
    geom_hline(yintercept = 0) +
    xlab("y") + ylab(expression('Residuals '~y-hat(y)))
}
plot_grid(
  hmof_partitioned_mod$plots$resid_normality,
  p_tob_mod$plots$resid_normality,
  plot_resid_vs_act(hmof_partitioned_mod$pred_df),
  plot_resid_vs_act(p_tob_mod$pred_df),
  ncol=2, nrow=2,
  labels=default_subfig_labels, label_size=12
  ) %>% 
  save_si_fig("residuals.png", ncol=2, nrow=2)

# Ranking of hMOF and ToBaCCo
plot_grid(
  hmof_partitioned_mod$plots$test_ranking,
  p_tob_mod$plots$test_ranking,
  ncol=2,
  labels=default_subfig_labels, label_size=12
  ) %>% 
  save_si_fig("ranking.png", ncol=2)

# Error breakdown by topology
p_err_topology <- 
  p_tob_mod$pred_df %>% 
  left_join(tobacco_data, by="id") %>% 
  ggplot(aes(y_act, y_pred)) + 
  geom_point() + parity_line +
  facet_wrap(~topology) +
  scale_x_continuous(breaks=scales::pretty_breaks(n=2)) +
  scale_y_continuous(breaks=scales::pretty_breaks(n=2)) +
  xlab("'Actual' uptake (GCMC simulations)") +
  ylab("Predicted uptake (ridge regression)") +
  coord_fixed()
p_err_topology %>% save_si_fig("err_by_topology.png", bheight=5)

```

### Model regularization strategies
```{r si_regularizaiton}
# Lambda plot from glmnet package.
# Viewing the source code with `plot.cv.glmnet` is very informative.
# See also an online vignette https://web.stanford.edu/~hastie/glmnet/glmnet_alpha.html#lin
set_li <- function(x, label, value) {
  # Sets the value of a labelled list item then returns the full list.
  # Pipe-friendly assignment for lists.  Use quotes around the label title
  x[[label]] <- value
  x
}
trained_mod$cv_for_lambda %>% 
  set_li("lambda.1se", NA) %>%  # Remove the 1SE line for clarity
  set_li(., "nzero", rep("", length(.$nzero))) %>%  # Hide the number of variables used
  plot
#recordPlot() %>%  # Thanks, https://github.com/wilkelab/cowplot/issues/69
#  plot_to_gtable() %>%  # requires gridGraphics
#  save_si_fig("lambda.png")
# This works, but it'll be easier to figure out labels, aspect, etc. if we just replot it.
# After all, we have the plot.cv.glmnet source code easily available.
p_si_lambda_lambdaval <- trained_mod$cv_for_lambda$lambda.min
p_si_lambda <- 
  trained_mod$cv_for_lambda %$% 
  qplot(log(lambda), cvm) +
  xlab("log(lambda)") +
  ylab("Mean-Squared Error") +
  geom_vline(xintercept=log(p_si_lambda_lambdaval), linetype="dashed")
p_si_lambda
p_si_lambda %>% save_si_fig("lambda.png")


# Combining LASSO, MLR, and ridge in a single figure
save_fig_table <- function(df, filename, digits=2, col_header = FALSE, parent_dir=default_fig_dir) {
  # Writes a table to a Latex file which can be read with \input
  # https://www.r-bloggers.com/exporting-r-tables-in-latex/
  df %>% 
    as.data.frame() %>%  # tibbles add a strange header to the file
    format(digits = digits) %>%  # Digits is only a suggestion
    write.table(
      file.path(parent_dir, filename),
      quote = FALSE,
      row.names = FALSE,
      col.names = col_header,
      eol="\\\\\n",
      sep=" & "
      )
}

trained_model_regu <- list(
  Ridge = hmof_partitioned_mod,
  # Ridge = run_model_on_partitions(hmof_hist_sets, hmof_y_to_join, default_binspec, 0),
  LASSO = run_model_on_partitions(hmof_hist_sets, hmof_y_to_join, default_binspec, 1),
  MLR = run_model_on_partitions(hmof_hist_sets, hmof_y_to_join, default_binspec, alpha=1, lambda=0, thresh=1e-16)
)

trained_model_regu %>% 
  set_li("Ridge", NULL) %>%  # We only need to plot LASSO and MLR here
  map2(., names(.), function(x,y) {x$plots$parity_testing + annotate("text", x=50, y=10, label=y)}) %>% 
  {do.call(  # For future reference, purrr:invoke is probably what I was looking for as a wrapper
    plot_grid,
    c(., list(  # https://stackoverflow.com/questions/25962605/how-to-add-more-arguments-of-a-function-in-do-call-in-r
      ncol=2,
      labels=default_subfig_labels, label_size=12
      )
    )
    )} %>% 
  save_si_fig("regu_parity.png", ncol=2)

trained_model_regu %>% 
  map_dfr(~ coef_tbl(.x$trained_mod$mod), .id="method") %>% 
  spread(method, beta) %>% 
  left_join(bin_loc_from_spec(default_binspec), by="bin") %>% 
  select(-bin) %>% 
  mutate(Bin=paste(lower, "to", upper, "kJ/mol")) %>% 
  mutate(Bin=ifelse(is.na(lower), "(Intercept)", Bin)) %>% 
  arrange(lower) %>% 
  select(Bin, Ridge, LASSO, MLR) %>% 
  save_fig_table("regu_coef.tex")

trained_model_regu %>%  # What are the lambda/alpha for the models?
  map_dfr(function(x) {list(lambda=x$trained_mod$lambda, alpha=x$trained_mod$alpha)}, .id="method")
  # If this is useful, gather then separate to add it to the previous DF, or a separate tex file.

```

### Consistency between different datasets
hMOF vs. ToBaCCo, etc.

```{r si_consistency}
# Comparison of beta coefficients from ridge regression for the two databases.
# This code will have a similar structure to plotting multiple temperatures or pressures.
p_coef_compare <- 
  list(`hMOF` = trained_mod$mod, `ToBaCCo` = p_tob_mod$trained_mod$mod) %>% 
  map_dfr(coef_tbl, .id="cat") %>%
  overlay_cat_betas(base_hist, ., default_binspec) +
  theme(legend.position=c(0, 0.2), legend.direction="horizontal")
p_coef_compare
p_coef_compare %>% save_si_fig("coef_compare.png", base_aspect_ratio = 1.5)


# TODO MORE

```





## Preparing CSD MOFs for screening
In order to successfully analyze the CSD MOFs, we need to filter out the purely metallic structures.  Those are only pseudo-materials of specially spatially-arranged atoms.  Since they aren't MOFs, the model does not predict them well, either.

Finding MOFs without carbon isn't too difficult.  Open Babel has a convenient [command line option](https://openbabel.org/docs/dev/Command-line_tools/babel.html#append-option) to print out the molecular formula.  Then, we can use some basic text processing tools within R to explore which structures contain carbon, oxygen, etc.

```
cd /cygdrive/c/Users/Benjamin/Git/EnergyGrid/BigData/cifs_from_csddata;
obabel *.cif -ab -otxt --append "\tFORMULA" >> ../csd_formula.txt
# Note, the output has multiple warnings about atom labels like '0', '1', and '1.'.
```

```{r csd_formula, eval=FALSE, include=FALSE}
# Temporarily disable this (expensive) section until we're ready to do the analysis.
# It might actually belong in a separate notebook file if influencing other steps in the analysis procedure.
raw_csd_formulas <- read_tsv(
  "BigData/csd_formula.txt",
  col_names = c("cif", "str_formula"),
  col_types = "cc"
  )
library(CHNOSZ)

# We can convert a purrr list to data.frame using dplyr::bind_rows.
# See also https://github.com/tidyverse/dplyr/issues/1676 for the as.list invocation,
# which converts each named vector into its own list
# TODO: consider using `safely` to parse or hide errors
csd_formulas <- 
  raw_csd_formulas$str_formula %>% 
  as.list %>% 
  map(makeup) %>% 
  map(as.list) %>% 
  bind_rows %>% 
  bind_cols(raw_csd_formulas, .)

# Let's implement a less stringent form of the CoRE MOF requirements.
# Here, we'll require MOFs to contain at least one of C, N, P, and S.
# First, how different are the results if we filter by has_"just C" instead of the whole set?
csd_formulas %>% filter(is.na(C) & is.na(N) & is.na(P) & is.na(S)) %>% nrow
csd_formulas %>% filter(is.na(C)) %>% nrow
# Based on that analysis, it's probably okay for a first pass to be less restrictive
print("Structures to remove (without C, N, P, or S):")
csd_formulas <- 
  csd_formulas %>% 
  mutate(missing_cnps = (is.na(C) & is.na(N) & is.na(P) & is.na(S)))
no_cnps <- csd_formulas %>%
  filter(missing_cnps) %>% 
  select(cif, str_formula)
no_cnps
no_cnps %>% 
  select(cif) %>% 
  write_tsv("BigData/Output/csd_mofs_without_cnps.txt", col_names = FALSE)

# Now to look at the CCDC GCMC results and predictions without the pure metals
ccdc_h2_grids %>% 
  filter(id %in% ccdc_gcmc$id) %>% 
  filter(!(id %in% no_cnps$cif)) %>% 
  eval_test_grid(trained_mod, ., default_binspec, mutate(ccdc_gcmc, y_act=g.L))

if (!exists("ccdc_predicted")) {
  ccdc_predicted <- pred_grid(trained_mod, ccdc_h2_grids, default_binspec)
}
ccdc_predicted %>% .$y_pred %>% hist()
print("Summary of top 1000:")
ccdc_predicted %>% 
  filter(!(id %in% no_cnps$cif)) %>% 
  .$y_pred %>%
  sort(decreasing=TRUE) %>% .[1:1000] %>%
  summary

csd_formulas %>% 
  filter(!missing_cnps) %>% 
  select(cif, str_formula) %>% 
  rename(id = cif) %>% 
  inner_join(ccdc_predicted, by="id") %>% 
  arrange(desc(y_pred)) %>% top_n(1000, y_pred)
# Based on looking at a few of the top structures, the cleaned up versions are 1D rods, so not likely synthesizable.  But that's more a flaw of the database than the screening method, though it's possible the prediction method may not work well for non-MOF structures.
```



## TODO notes from meetings
### General
* Add Scotty's new ToBaCCo FH data
* Consider expanding H2 and CH4 grids for the full hMOF database to plot in the paper.
* Recalculate the beta robustness figure
* Figure out beta plots without normalization.  Set `zscore=FALSE` as default for `fit_glmnet`
* Send Scotty list of top CCDC candidates once we have a (near-final?) model.  Should also check for applicability of metallics vs. standard MOFs
* Calculate density for the hMOFs (and consider recalculating all of the textural properties in Zeo++)
* See base case analysis above for plain textural properties.  Understand the limitations of MLR on CH4 (vs. H2).
* Saving the manuscript/SI figures should also print them (maybe with a global flag to disable)
* Label Q2 and RMSE on plots. (easy: adjust the sub$plot)  Maybe also source of data (in the color): "Training\n1000 hMOFs" etc.
* Try to break Q2=0 with small n.  How low can we go?  Is 1000 samples way too many for this?
* Violin plots

### Model formulation
* Consider setting the model intercept to zero
* Recalculate Q2 once we relax the penalty term to be lower.  Beyond RMSE, etc., how does Q2 vary for the models

### Figures 
* Also add Spearman and/or Kendall to the ranking plot.  In general, numbers referenced in the text should also be aggregated in their own code block to make it easier to update the text.
* Beta plot: consider drawing the background as the average histogram of the data.  Betas could be drawn as hlines instead of dots.
* For beta plots with multiple values, also consider making the points B&W friendly (shape, etc?)

### Other from group meeting 12/7
* What about higher T for desorption?
* How do the range of the hMOF and ToBaCCo energies compare?  Is the maximally attractive ToBaCCo region significantly lower than the hMOFs? (related: does our ToBaCCo energy go low enough?)
* Can we optimize uptake for a given bin (calculating a maximum adsorption for an artificial pseudo-MOF using the histogram bins?)

#### Other possible directions
* What sort of capacity could you get with a uniform background potential? (`12_6_2_0` potential against a single MOF pseudo atom in a huge box?  Of course no tail corrections or shifting the potential (or 12/6 LJ params)).  Of course, validate against a bias of 0 kJ/mol to verify that the "deliverable capacity" is just the difference in 100 bar and 2 bar densities. (in curiosity, how closely does the "density" of the pseudobox match the beta coefficient for each raw bin?)
* Make a few parity plots from the Q2 analysis.  Is the good prediction consistent across histogram parameters?  How about for ToBaCCo, since it's likely more sensitive?
* Is there a relationship between the betas at different P/T?  That could help optimize operating parameters if we can interpolate predictive models.
* Use Wilmer's CH4 data to compare against the chemical intutition paper?
